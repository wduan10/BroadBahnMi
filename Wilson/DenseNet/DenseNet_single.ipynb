{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "799b5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing\n",
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "print('Importing')\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from DenseNet_model import DenseNet\n",
    "from PIL import Image\n",
    "print('Done importing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79900b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathology = 'Enlarged Cardiomediastinum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a10489a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/wilsonduan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '--f=/Users/wilsonduan/Library/Jupyter/runtime/kernel-v2-873UbFJ7XaRsHet.json']\n"
     ]
    }
   ],
   "source": [
    "hpc = False\n",
    "print(sys.argv)\n",
    "if (len(sys.argv) > 1 and sys.argv[1] == 'hpc'):\n",
    "    hpc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ffe4eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False cpu 20\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0002\n",
    "n_epochs = 20\n",
    "batch_size = 128\n",
    "device = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
    "print(hpc, device, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5aac594-8372-4140-a1b5-38767290c2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Path  Enlarged Cardiomediastinum\n",
      "5    train/pid17532/study1/view1_frontal.jpg                        -1.0\n",
      "6    train/pid17532/study1/view2_lateral.jpg                        -1.0\n",
      "7    train/pid05208/study1/view1_frontal.jpg                        -1.0\n",
      "9    train/pid35409/study2/view1_frontal.jpg                         1.0\n",
      "14  train/pid18261/study13/view1_frontal.jpg                        -1.0\n",
      "   Unnamed: 0  Id                                    Path\n",
      "0           0  18  test/pid56785/study1/view1_frontal.jpg\n",
      "1           1  19  test/pid56785/study1/view2_lateral.jpg\n",
      "2           2  44  test/pid57943/study1/view1_frontal.jpg\n",
      "3           3  45  test/pid57943/study2/view1_frontal.jpg\n",
      "4           4  57  test/pid54805/study1/view1_frontal.jpg\n"
     ]
    }
   ],
   "source": [
    "if (hpc):\n",
    "    labels_path_train = '/groups/CS156b/data/student_labels/train2023.csv'\n",
    "    labels_path_test = '/groups/CS156b/data/student_labels/test_ids.csv'\n",
    "    img_dir = '/groups/CS156b/data'\n",
    "\n",
    "    df_train = pd.read_csv(labels_path_train)[:-1]\n",
    "else:\n",
    "    labels_path_train = 'data/train/labels/labels.csv'\n",
    "    labels_path_test = 'data/test/ids.csv'\n",
    "    img_dir = 'data'\n",
    "\n",
    "    df_train = pd.read_csv(labels_path_train)\n",
    "\n",
    "df_train = df_train[['Path', pathology]]\n",
    "df_train = df_train.dropna()\n",
    "df_test = pd.read_csv(labels_path_test)\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "527b3983-b2e2-472f-a96f-e3238a8b7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(df):\n",
    "    df = df[['Path', pathology]]\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "class TrainImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        if (hpc):\n",
    "            self.img_labels = parse_labels(pd.read_csv(annotations_file)[:-1])\n",
    "        else:\n",
    "            self.img_labels = parse_labels(pd.read_csv(annotations_file))\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.img_labels.iloc[idx]\n",
    "\n",
    "        img_path = row['Path']\n",
    "        img_path = os.path.join(self.img_dir, img_path)\n",
    "\n",
    "        image = Image.open(img_path) # PIL image for applying transform for pre-trained ResNet model \n",
    "        label_num = row[-1] + 1 # -1 => 0, 0 => 1, 1 => 2\n",
    "        label = torch.tensor(label_num).long()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.img_labels.iloc[idx]\n",
    "\n",
    "        img_path = row['Path']\n",
    "        img_path = os.path.join(self.img_dir, img_path)\n",
    "\n",
    "        # image = read_image(img_path)\n",
    "        image = Image.open(img_path) # PIL image for applying transform for pre-trained ResNet model \n",
    "        label = row['Id']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "954a7acf-91f0-4f56-9ff9-ab2b1c98cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default transform:\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# transform with random flipping and cropping:\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "#     transforms.Resize((300, 300)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomCrop((256, 256))\n",
    "# ])\n",
    "\n",
    "# transform with Gaussian blur:\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "#     transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "# ])\n",
    "\n",
    "training_data = TrainImageDataset(labels_path_train, img_dir, transform=transform)\n",
    "test_data = TestImageDataset(labels_path_test, img_dir, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "training_data, val_data = torch.utils.data.random_split(training_data, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a778d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet(channels=3, growth_rate=16, num_classes=3)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce98d392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wilsonduan/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1623459064158/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([5, 3])\n",
      "label torch.Size([5])\n",
      "Training Loss: 1.0962\n",
      "Validation loss: 1.0336\n",
      "Epoch 2/20:\n",
      "output torch.Size([5, 3])\n",
      "label torch.Size([5])\n",
      "Training Loss: 0.9769\n",
      "Validation loss: 0.9794\n",
      "Epoch 3/20:\n",
      "output torch.Size([5, 3])\n",
      "label torch.Size([5])\n",
      "Training Loss: 0.8731\n",
      "Validation loss: 0.9748\n",
      "Epoch 4/20:\n",
      "output torch.Size([5, 3])\n",
      "label torch.Size([5])\n",
      "Training Loss: 0.8031\n",
      "Validation loss: 0.9836\n",
      "Epoch 5/20:\n",
      "output torch.Size([5, 3])\n",
      "label torch.Size([5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e2f846ae43be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# store metrics\n",
    "training_loss_history = np.zeros(n_epochs)\n",
    "validation_loss_history = np.zeros(n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}:')\n",
    "    # train\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(images)\n",
    "        # calculate categorical cross entropy loss\n",
    "        print('output', output.shape)\n",
    "        print('label', labels.shape)\n",
    "        loss = criterion(output, labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # track training loss\n",
    "        training_loss_history[epoch] += loss.item()\n",
    "    \n",
    "    training_loss_history[epoch] /= len(train_dataloader)\n",
    "    print(f'Training Loss: {training_loss_history[epoch]:0.4f}')\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # forward pass\n",
    "            output = model(images)\n",
    "            # find loss\n",
    "            loss = criterion(output, labels)\n",
    "            validation_loss_history[epoch] += loss.item()\n",
    "        validation_loss_history[epoch] /= len(val_dataloader)\n",
    "    print(f'Validation loss: {validation_loss_history[epoch]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6ed2c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Enlarged Cardiomediastinum\n",
       "0  18                           1\n",
       "1  19                           1\n",
       "2  44                           1\n",
       "3  45                           1\n",
       "4  57                           1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions on test set\n",
    "rows_list = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        images, ids = data\n",
    "        images, ids = images.to(device), ids.to(device)\n",
    "        \n",
    "        output = np.array(model(images).cpu())\n",
    "        output = np.argmax(output, axis=1) - 1\n",
    "        for preds, id in zip(output, ids):\n",
    "            rows_list.append([int(id)] + [preds])\n",
    "\n",
    "df_output = pd.DataFrame(rows_list, columns=['Id', pathology])\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "485a5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (hpc):\n",
    "    output_dir = '/groups/CS156b/2024/BroadBahnMi/predictions'\n",
    "else:\n",
    "    output_dir = 'predictions'\n",
    "\n",
    "filename = '_'.join(pathology.split())\n",
    "full_path = os.path.join(output_dir, f'preds_{filename}.csv')\n",
    "df_output.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f394e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
