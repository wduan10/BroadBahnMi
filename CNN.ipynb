{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "799b5107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing\n",
      "Done importing\n"
     ]
    }
   ],
   "source": [
    "print('Importing')\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "print('Done importing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a10489a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/wilsonduan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py', '--f=/Users/wilsonduan/Library/Jupyter/runtime/kernel-v2-629x0Ex4Mk1Pv7m.json']\n"
     ]
    }
   ],
   "source": [
    "hpc = False\n",
    "print(sys.argv)\n",
    "if (len(sys.argv) > 1 and sys.argv[1] == 'hpc'):\n",
    "    hpc = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ffe4eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False cpu 3\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0002\n",
    "n_epochs = 5 if hpc else 3\n",
    "batch_size = 64\n",
    "device = torch.device('cuda' if (torch.cuda.is_available()) else 'cpu')\n",
    "print(hpc, device, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e5aac594-8372-4140-a1b5-38767290c2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
      "0           0             0               0                 0   \n",
      "1           1             1               1                 1   \n",
      "2           2             2               2                 2   \n",
      "3           3             3               3                 3   \n",
      "4           4             4               4                 4   \n",
      "\n",
      "   Unnamed: 0.1.1.1.1                                     Path     Sex  Age  \\\n",
      "0                   0  train/pid50512/study1/view1_frontal.jpg  Female   68   \n",
      "1                   1  train/pid21580/study2/view1_frontal.jpg  Female   87   \n",
      "2                   2  train/pid21580/study1/view1_frontal.jpg  Female   83   \n",
      "3                   3  train/pid21580/study1/view2_lateral.jpg  Female   83   \n",
      "4                   4  train/pid33839/study1/view1_frontal.jpg    Male   41   \n",
      "\n",
      "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
      "0         Frontal    AP         1.0                         NaN           NaN   \n",
      "1         Frontal    AP        -1.0                         NaN           0.0   \n",
      "2         Frontal    AP        -1.0                         NaN           NaN   \n",
      "3         Lateral   NaN        -1.0                         NaN           NaN   \n",
      "4         Frontal    AP        -1.0                         NaN           NaN   \n",
      "\n",
      "   Lung Opacity  Pneumonia  Pleural Effusion  Pleural Other  Fracture  \\\n",
      "0           NaN        NaN               NaN            NaN       NaN   \n",
      "1           1.0        NaN               0.0            NaN       1.0   \n",
      "2           1.0        NaN               NaN            NaN       1.0   \n",
      "3           1.0        NaN               NaN            NaN       1.0   \n",
      "4           NaN        NaN               NaN            NaN       NaN   \n",
      "\n",
      "   Support Devices  \n",
      "0              1.0  \n",
      "1              NaN  \n",
      "2              NaN  \n",
      "3              NaN  \n",
      "4              NaN  \n",
      "   Unnamed: 0  Id                                    Path\n",
      "0           0  18  test/pid56785/study1/view1_frontal.jpg\n",
      "1           1  19  test/pid56785/study1/view2_lateral.jpg\n",
      "2           2  44  test/pid57943/study1/view1_frontal.jpg\n",
      "3           3  45  test/pid57943/study2/view1_frontal.jpg\n",
      "4           4  57  test/pid54805/study1/view1_frontal.jpg\n"
     ]
    }
   ],
   "source": [
    "if (hpc):\n",
    "    labels_path_train = '/groups/CS156b/data/student_labels/train2023.csv'\n",
    "    labels_path_test = '/groups/CS156b/data/student_labels/test_ids.csv'\n",
    "    img_dir = '/groups/CS156b/data'\n",
    "\n",
    "    df_train = pd.read_csv(labels_path_train)[:-1]\n",
    "else:\n",
    "    labels_path_train = 'data/train/labels/labels.csv'\n",
    "    labels_path_test = 'data/test/ids.csv'\n",
    "    img_dir = 'data'\n",
    "\n",
    "    df_train = pd.read_csv(labels_path_train)\n",
    "\n",
    "df_test = pd.read_csv(labels_path_test)\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "527b3983-b2e2-472f-a96f-e3238a8b7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(df):\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "class TrainImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        if (hpc):\n",
    "            self.img_labels = parse_labels(pd.read_csv(annotations_file)[:-1])\n",
    "        else:\n",
    "            self.img_labels = parse_labels(pd.read_csv(annotations_file))\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.img_labels.iloc[idx]\n",
    "\n",
    "        img_path = row['Path']\n",
    "        img_path = os.path.join(self.img_dir, img_path)\n",
    "\n",
    "        image = Image.open(img_path) # PIL image for applying transform for pre-trained ResNet model \n",
    "        label = torch.tensor(list(row[-9:])).float() # extract label, the last 9 columns\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.img_labels.iloc[idx]\n",
    "\n",
    "        img_path = row['Path']\n",
    "        img_path = os.path.join(self.img_dir, img_path)\n",
    "\n",
    "        # image = read_image(img_path)\n",
    "        image = Image.open(img_path) # PIL image for applying transform for pre-trained ResNet model \n",
    "        label = row['Id']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "954a7acf-91f0-4f56-9ff9-ab2b1c98cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform for ResNet \n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "training_data = TrainImageDataset(labels_path_train, img_dir, transform=transform)\n",
    "test_data = TestImageDataset(labels_path_test, img_dir, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(training_data))\n",
    "val_size = len(training_data) - train_size\n",
    "training_data, val_data = torch.utils.data.random_split(training_data, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3a778d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample model with dropout = 0.1\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 8, kernel_size=(3, 3)),\n",
    "    nn.BatchNorm2d(num_features=8),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Dropout(p=0.1),\n",
    "\n",
    "    nn.Conv2d(8, 4, kernel_size=(3, 3)),\n",
    "    nn.BatchNorm2d(num_features=4),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Dropout(p=0.1),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(62*62*4, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 9),\n",
    "    # PyTorch implementation of cross-entropy loss includes softmax layer\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce98d392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "Training Loss: 0.4874\n",
      "Validation loss: 0.4344\n",
      "Epoch 2/3:\n",
      "Training Loss: 0.4219\n",
      "Validation loss: 0.4430\n",
      "Epoch 3/3:\n",
      "Training Loss: 0.6246\n",
      "Validation loss: 0.4427\n"
     ]
    }
   ],
   "source": [
    "# store metrics\n",
    "training_loss_history = np.zeros(n_epochs)\n",
    "validation_loss_history = np.zeros(n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}:')\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    # train\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(images)\n",
    "        # calculate categorical cross entropy loss\n",
    "        loss = criterion(output, labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # track training loss\n",
    "        training_loss_history[epoch] += loss.item()\n",
    "    \n",
    "    training_loss_history[epoch] /= len(train_dataloader)\n",
    "    print(f'Training Loss: {training_loss_history[epoch]:0.4f}')\n",
    "\n",
    "    # validate\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for i, data in enumerate(val_dataloader):\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # forward pass\n",
    "            output = model(images)\n",
    "            # find loss\n",
    "            loss = criterion(output, labels)\n",
    "            validation_loss_history[epoch] += loss.item()\n",
    "        validation_loss_history[epoch] /= len(val_dataloader)\n",
    "    print(f'Validation loss: {validation_loss_history[epoch]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e6ed2c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.016223</td>\n",
       "      <td>0.040410</td>\n",
       "      <td>-0.135655</td>\n",
       "      <td>-0.078722</td>\n",
       "      <td>0.042815</td>\n",
       "      <td>0.082322</td>\n",
       "      <td>-0.089271</td>\n",
       "      <td>-0.048631</td>\n",
       "      <td>-0.074479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.034654</td>\n",
       "      <td>-0.104364</td>\n",
       "      <td>-0.080133</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>-0.116951</td>\n",
       "      <td>-0.038940</td>\n",
       "      <td>-0.099944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.035175</td>\n",
       "      <td>-0.119291</td>\n",
       "      <td>-0.077042</td>\n",
       "      <td>0.043481</td>\n",
       "      <td>0.089147</td>\n",
       "      <td>-0.091824</td>\n",
       "      <td>-0.042777</td>\n",
       "      <td>-0.084437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>0.013780</td>\n",
       "      <td>0.028915</td>\n",
       "      <td>-0.125448</td>\n",
       "      <td>-0.074006</td>\n",
       "      <td>0.044283</td>\n",
       "      <td>0.076240</td>\n",
       "      <td>-0.086288</td>\n",
       "      <td>-0.042548</td>\n",
       "      <td>-0.086567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0.028089</td>\n",
       "      <td>0.035412</td>\n",
       "      <td>-0.113717</td>\n",
       "      <td>-0.078328</td>\n",
       "      <td>0.049569</td>\n",
       "      <td>0.076105</td>\n",
       "      <td>-0.105156</td>\n",
       "      <td>-0.035963</td>\n",
       "      <td>-0.090809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  Lung Opacity  \\\n",
       "0  18    0.016223                    0.040410     -0.135655     -0.078722   \n",
       "1  19    0.025537                    0.034654     -0.104364     -0.080133   \n",
       "2  44    0.005224                    0.035175     -0.119291     -0.077042   \n",
       "3  45    0.013780                    0.028915     -0.125448     -0.074006   \n",
       "4  57    0.028089                    0.035412     -0.113717     -0.078328   \n",
       "\n",
       "   Pneumonia  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
       "0   0.042815          0.082322      -0.089271 -0.048631        -0.074479  \n",
       "1   0.061497          0.059436      -0.116951 -0.038940        -0.099944  \n",
       "2   0.043481          0.089147      -0.091824 -0.042777        -0.084437  \n",
       "3   0.044283          0.076240      -0.086288 -0.042548        -0.086567  \n",
       "4   0.049569          0.076105      -0.105156 -0.035963        -0.090809  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions on test set\n",
    "rows_list = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        images, ids = data\n",
    "        images, ids = images.to(device), ids.to(device)\n",
    "        \n",
    "        output = model(images)\n",
    "        for preds, id in zip(output, ids):\n",
    "            preds = [float(x) for x in preds]\n",
    "            rows_list.append([int(id)] + list(preds))\n",
    "\n",
    "df_output = pd.DataFrame(rows_list, columns=['Id'] + list(df_train.columns[-9:]))\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "485a5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (hpc):\n",
    "    output_dir = '/groups/CS156b/2024/BroadBahnMi/predictions'\n",
    "else:\n",
    "    output_dir = 'predictions'\n",
    "\n",
    "number = 1\n",
    "for file in os.listdir(output_dir):\n",
    "    if (file[:5] == 'preds'):\n",
    "        number = max(number, int(file[6:-4]) + 1)\n",
    "\n",
    "full_path = os.path.join(output_dir, f'preds_{number}.csv')\n",
    "df_output.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f234f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
